---
title: Los riesgos de la delegación automática
tags: [personal]
header_image: dashboard-rules-cheating.jpg
reviewed: true
ai: true
---
La inteligencia artificial está transformando rápidamente muchas áreas de la sociedad. En el ámbito educativo, sin embargo, el enfoque hacia esta tecnología sigue siendo más cauteloso que entusiasta. A pesar del potencial de la IA para revolucionar el aprendizaje, muchas universidades e instituciones académicas continúan imponiendo restricciones que, en lugar de fomentar un uso crítico y consciente de la IA, la tratan como una amenaza.

Mientras que algunas instituciones ven en la IA una amenaza a la integridad académica, otras están adoptando enfoques restrictivos, limitando su uso en las aulas. Este tipo de respuesta refleja una resistencia al cambio, más que un intento serio de explorar las oportunidades que esta tecnología puede ofrecer. Recientemente, se ha visto que algunas universidades en EE.UU. han comenzado a rechazar aplicaciones para el otoño de 2025 tras detectar el uso de IA en los ensayos de los estudiantes. Esta política, además de limitar el desarrollo de habilidades críticas, corre el riesgo de sesgarse contra estudiantes internacionales, ya que los algoritmos de detección de IA no siempre son justos y precisos en todos los contextos lingüísticos y culturales. En lugar de prohibir su uso, las universidades deberían enfocarse en enseñar a los estudiantes cómo utilizar la IA para potenciar sus habilidades, no para reemplazarlas. (Referencia: [post de LinkedIn](https://www.linkedin.com/posts/nirmalthacker_shocked-to-see-universities-in-usa-handing-activity-7254707298755854336-rbt2?utm_source=share&utm_medium=member_desktop))

# El estado actual: prohibición en lugar de integración
En muchas universidades, la respuesta más común al avance de la IA ha sido la prohibición. Las políticas universitarias han comenzado a multiplicar los mensajes de "prohibido utilizar IA" en la entrega de trabajos académicos, con la insistencia de que todo contenido debe ser completamente original. Estas posturas parten de preocupaciones legítimas sobre la integridad académica y el riesgo de plagio, pero ignoran el potencial de la IA como una herramienta educativa.

En lugar de prohibir su uso, las universidades deberían enfocarse en enseñar a los estudiantes cómo utilizar la IA para potenciar sus habilidades, no para reemplazarlas. La IA puede servir como una herramienta para aumentar la productividad, ayudando a automatizar tareas rutinarias y permitiendo que los estudiantes se concentren en tareas más complejas y creativas. Esto no significa que se deba delegar todo a la IA, sino que su uso debe ir acompañado de una enseñanza crítica que fomente un pensamiento equilibrado.

En el episodio del podcast *Behind the Tech*, Sal Khan, fundador de Khan Academy, menciona cómo la IA puede utilizarse no solo para apoyar el aprendizaje de los estudiantes, sino también para mitigar los riesgos de trampa académica. Khan sugiere que la IA puede actuar como un "coach de escritura ético", ayudando a los estudiantes a mejorar sus habilidades sin hacer el trabajo por ellos. Además, el sistema podría identificar si un estudiante ha utilizado una IA externa para generar su trabajo y alertar al profesor cuando el estilo de escritura no coincida con trabajos anteriores. Como él afirma: "la IA puede usarse para socavar la trampa generada por la IA" (Behind the Tech, episodio con Sal Khan, 2023).

# El caso del código: ¿Nos volvemos mediocres al utilizar IA?
En el campo de la programación, el uso de IA ha generado una preocupación adicional: la mediocridad de los resultados. Debido a que los modelos de lenguaje como GPT se entrenan con datos disponibles públicamente, el código que generan tiende a ser promedio. Esto significa que las soluciones más avanzadas y optimizadas, que suelen ser propietarias o altamente especializadas, no están al alcance de estos sistemas, lo que resulta en soluciones más “normales”.

Sin embargo, prohibir el uso de IA en la enseñanza de programación no es la solución adecuada. Es importante enseñar a los estudiantes a reconocer las limitaciones del código generado por IA y a saber cuándo es necesario optimizarlo o incluso descartar la solución propuesta por la máquina. La IA puede ser una excelente herramienta para tareas simples o para aprender los fundamentos de la programación, pero su verdadero valor surge cuando los estudiantes desarrollan habilidades críticas y saben cómo mejorar lo que la IA les ofrece.

# La colaboración activa con la IA
En el ámbito profesional, la IA está redefiniendo cómo se trabaja y se colaborará en el futuro. En lugar de simplemente utilizar la IA como una herramienta, empresas y profesionales han comenzado a abordarla como un "colega" con el que se co-crea, en lugar de delegar a ciegas. La clave está en que los usuarios aporten contexto, instrucciones detalladas y retroalimentación continua. Tal como describe el líder de Microsoft Jared Spataro, la IA representa un cambio profundo en la relación entre personas y tecnología, moviéndose hacia una colaboración activa que requiere habilidades de supervisión y dirección, no solo de uso instrumental. Este modelo de co-creación, más común en el mundo profesional, es un concepto que también debería implementarse en la educación para aprovechar el potencial de la IA sin que los estudiantes pierdan sus habilidades fundamentales. (Referencia: [artículo de Spataro](https://www.microsoft.com/en-us/worklab/work-with-ai-like-its-a-colleague-not-a-calculator))

# Soluciones para un uso consciente y crítico de la IA en la educación
Para aprovechar los beneficios de la IA sin sacrificar el desarrollo de habilidades cognitivas clave, es necesario implementar varias estrategias en el sistema educativo:

Educación sobre la IA y su funcionamiento: Los estudiantes deben aprender cómo funcionan las IA, los algoritmos detrás de ellas y sus limitaciones. Este conocimiento es fundamental para utilizarlas de manera crítica y eficaz, tanto en el aula como en el ámbito laboral.

Fomentar el pensamiento crítico: La IA no siempre produce soluciones óptimas, por lo que es esencial enseñar a los estudiantes a evaluar críticamente las respuestas generadas. En lugar de aceptar ciegamente las soluciones proporcionadas, los estudiantes deben aprender a analizarlas y mejorarlas.

Uso complementario de la IA: La IA no debe reemplazar el esfuerzo humano, sino complementarlo. Por ejemplo, en la redacción o programación, la IA puede ayudar con ideas iniciales o con tareas rutinarias, pero los estudiantes deben refinar el trabajo final y añadir su propia creatividad.

Evaluaciones híbridas: Las tareas académicas deberían diseñarse de manera que requieran tanto el uso de la IA como la aplicación de habilidades humanas. Esto garantiza que los estudiantes no solo usen la IA para automatizar el trabajo, sino que también desarrollen habilidades críticas y analíticas.

Desarrollo de habilidades para la delegación de IA: Tal como sugiere Marr, aprender a delegar tareas de manera efectiva a la IA será una habilidad crucial en el futuro. Esto incluye la capacidad de entender qué tareas pueden ser delegadas y cuáles requieren la intervención humana.

Ética y responsabilidad en el uso de IA: Los estudiantes también deben aprender sobre los aspectos legales y éticos del uso de la IA, incluyendo la privacidad, el manejo de datos y la necesidad de evitar sesgos en los algoritmos. El uso responsable de la IA es clave para garantizar que estas herramientas sean utilizadas de manera justa y ética.

# El futuro de la IA en la educación
La integración de la IA en la educación es inevitable. Las universidades no pueden permitirse ignorar una tecnología que está cambiando radicalmente la forma en que trabajamos y aprendemos. En lugar de prohibir la IA, deberían centrarse en formar a estudiantes capaces de utilizarla de manera crítica y creativa, aprovechando sus fortalezas sin perder de vista la importancia del juicio humano.

Como bien señala Bernard Marr, la delegación de tareas a la IA no es solo una cuestión de productividad; es también una forma de liberar tiempo para actividades que realmente requieren habilidades humanas, como la innovación, la creatividad y la resolución de problemas complejos. La clave no es evitar la IA, sino aprender a utilizarla de manera que complemente y potencie nuestras capacidades. Solo así podremos formar a la próxima generación de líderes y profesionales, preparados para enfrentar un mundo donde la IA será una parte integral de sus vidas.

# Referencias
- [Post de LinkedIn](https://www.linkedin.com/posts/nirmalthacker_shocked-to-see-universities-in-usa-handing-activity-7254707298755854336-rbt2?utm_source=share&utm_medium=member_desktop)
- [Artículo de Spataro](https://www.microsoft.com/en-us/worklab/work-with-ai-like-its-a-colleague-not-a-calculator)
- https://www.forbes.com/sites/bernardmarr/2023/06/19/ai-delegation-the-one-skill-you-will-need-to-succeed-in-the-future/

--- 

Espero que este ajuste sea útil para destacar la relevancia de estos enfoques en la relación entre la IA y la educación.


---
https://www.linkedin.com/posts/nirmalthacker_shocked-to-see-universities-in-usa-handing-activity-7254707298755854336-rbt2?utm_source=share&utm_medium=member_desktop


Shocked to see Universities in USA handing out rejection letters for Fall 2025 based on AI detection in Essays! 

Sharing this letter a student got with their permission.
Student and University details obscured for privacy reasons.

While I believe you should write your own essays and this is why GradPilot is designed to be a counselor rather than an essay writer, AI detection is fundamentally flawed and especially biased against international students.

Stanford researchers have already established this - https://lnkd.in/dA5ZuBBp

And several universities have disabled AI detection in students homeworks, such as:

Vanderbilt - https://lnkd.in/dU36JqDa

NYU - https://lnkd.in/d89EegfJ

Oregon State - https://lnkd.in/dxS25nkH

Hope other universities see this biased method of disqualifying otherwise talented students 🙏


---
Spataro: https://www.microsoft.com/en-us/worklab/work-with-ai-like-its-a-colleague-not-a-calculator

Three weeks ago, I dropped off my fourth and youngest child at college—the same school his mom and I both attended back in the ’90s. On the one hand, I was struck by how familiar it all felt. He now lives in the same dorm his mom did during her freshman year, which still has the familiar fluorescent lighting and linoleum floors.

But as recognizable as his environment feels to me now, I know that the world he’ll step into after graduation will be very different from the one in which I had my first work experiences.

AI is creating a seismic shift in the way humans spend their time—reshaping entire workflows and patterns that have long defined the workday.

One new pattern that’s emerging reflects a fundamental evolution in our relationship to personal technology: to use AI effectively, you need to collaborate with it as if you’re working with a colleague—not a calculator.

From command to conversation
From the days of vacuum tubes and punch cards, computing has always followed the same command-and-control pattern. Humans give an instruction (“input”), and the computer obeys (“output”). Calculators work this way (“solve this math problem”), and until recently, internet search worked the same way (“find the relevant web page”).

When AI first came to work, most of us had yet to understand that this paradigm was about to be flipped on its head. Even 18 months ago when we introduced Copilot, “prompt and response” thinking was still the rule—type in the right combination of words or phrases and expect a result that felt like magic.

Since then, people who put AI to work have learned that the most effective way to collaborate with it is more iterative and layered. It’s a conversation, not a command.

Say you need Copilot to help you build a product pitch deck. If you offer up a single prompt (even a detailed one), Copilot likely won’t generate a finished presentation that meets your needs.

You get the best results when you work iteratively—or “co-create”—with AI. You add details. You point Copilot to relevant files, and it comes back with an outline that you can adjust, add to, and reorder.

When you’re ready, Copilot will generate slides that you can edit. That same process can shape every step of deck creation, from formatting to illustration. Co-creation gets people to a satisfying, useful product.

Learning and unlearning
This new human-AI collaboration pattern requires learning new skills and habits—and unlearning others. We’ll need to move beyond the “calculator approach” of working with technology. Instead, we’ll learn to collaborate with AI—something that looks an awful lot like collaborating with other humans. In fact, to co-create with AI you need to tap into the same skills that leaders use to supervise and guide employees.

When you’re managing someone, you don’t take a one-shot approach: “Here’s an assignment. I hope you get it right on the first try.” Instead, you become a coach. You set expectations, review the work, and provide feedback. Rinse and repeat.

The same holds true with AI. You need to know how to give the right context in a prompt, which means distilling what background information is helpful and what’s just noise. You might need to clarify your instructions. You evaluate the output. When the response is off, you redirect to get to the best outcome.

Soon enough, this mode of co-creation will begin to reshape organizations, where even the most junior employees will become managers of multiple AI agents. Everyone will orchestrate them to take mundane tasks off their plates and leverage AI’s expertise to generate more value more quickly and at a much lower cost.

What’s next
In this transformation made possible by co-creation, I see a tremendous opportunity for employees and leaders at every stage of their careers.

The first “generation AI” graduates will enter the workforce with an almost native understanding of the collaborative back-and-forth that AI requires. They’ll understand the value of delegating tedious, time-consuming entry-level work to AI—which will free up their own time and energy for higher order tasks, whether they’re crafting strategies for their first job interview or building their first companies.

Meanwhile, more tenured employees can put their existing management skills to new use with AI, building capacity for themselves and their teams so they can scale their impact like never before.

Regardless of your role or placement on the org chart, AI will level the playing field for every employee. With AI, everyone can be a data analyst, a designer, or an editor. And everyone will be able to delegate items from their to-do list to AI, opening the door to more impactful and strategic work. And everyone will start to co-create with AI and human colleagues at the same time, an emerging pattern that promises to amplify team creativity and productivity.

Summing it up
With AI, work is transitioning from people using technology as tools to people working alongside technology as colleagues. Co-creation is how we will all manage that new relationship. This pattern is already altering our day-to-day experience of work. Soon it will shift the long-term arc of careers, for everyone from new college graduates to senior executives. With help from AI, we’ll all take on work that’s more strategic, meaningful, and, hopefully, more inspiring.
---