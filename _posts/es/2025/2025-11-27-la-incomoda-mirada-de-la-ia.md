---
title: La incómoda mirada de la IA
tags: [personal, artificial_intelligence]
reviewed: true
home: true
ai: true
header_image: ai-driven-leader.jpg
---
Trabajar con IA suele tener un efecto curioso. Siempre te acompaña, siempre confirma, siempre suaviza. Si se equivoca, pide disculpas. Si afirmas algo cuestionable, intenta justificarlo. Si le pides una opinión, se asegura de no contrariarte demasiado. Todos hemos experimentado esta especie de condescendencia digital que hace que la IA parezca útil, pero también sorprendentemente complaciente.

The *AI-Driven Leader* no es un libro sobre tecnología. Es un libro sobre cómo pensamos cuando la inteligencia artificial entra en escena. Presenta la IA como entrevistador, comunicador y desafiante, y lo relevante no es la clasificación, sino lo que ocurre cuando empiezas a usar la IA de esa manera. Ahí surge una claridad incómoda que te obliga a revisar tus ideas y tu forma de pensar. Porque pensar con IA no debería hacerte más rápido, debería hacerte más exigente.

En mi dia a dia he comprobado que la IA puede incomodarte de una forma muy productiva. Esa incomodidad no aparece cuando la IA hace resúmenes, redacta textos o procesa datos. Aparece cuando le pides que piense contigo, o peor aún, contra ti. 

Una de las formas más útiles de trabajar con la IA es pedirle que actúe como entrevistador. Lo hago constantemente, especialmente cuando preparo propuestas para clientes. No espero que una IA construya una propuesta perfecta a partir de unos requisitos, pero sí quiero que me ayude a estructurar lo básico y, sobre todo, que me ponga a prueba. Un prompt que aparece en el libro encaja muy bien con este enfoque: “Entrevístame como si fueras un consultor externo y ayúdame a identificar supuestos no validados, riesgos ocultos y puntos débiles en mi planteamiento.” La primera vez que lo apliqué a una propuesta de identidad que ya tenía avanzada, la IA abrió con una pregunta sencilla pero incisiva: “¿Qué supuestos sobre el cliente no has validado todavía?”. Esa sola pregunta desmontó una parte del planteamiento que yo daba por buena. No es agradable descubrir que has construido algo sobre un supuesto frágil, pero siempre es mejor verlo antes de presentarlo. Esa es la incomodidad que realmente impulsa a pensar mejor.

Otra forma útil de trabajar con la IA es pedirle que actúe como comunicador, sobre todo cuando necesito compartir un análisis complejo con un grupo de trabajo que no vive el detalle técnico. A veces el exceso de información se convierte en una barrera y no en una ayuda. Un prompt que aparece en el libro refleja bien este enfoque: “Reformula este contenido para que cualquier miembro del equipo pueda entender el contexto, el impacto y las decisiones clave sin perder precisión.” Al aplicarlo, la IA depura el mensaje hasta dejar únicamente lo esencial, y eso también genera cierta incomodidad. Obliga a priorizar, a dejar de lado lo accesorio y a centrarse en lo que realmente importa. Esa claridad no simplifica el problema, lo expone. Y cuando un texto deja de esconderse en complejidades innecesarias, las decisiones aparecen inevitablemente en primer plano.

Pero donde el libro sí plantea un punto especialmente útil es en el uso de la IA como desafiante. Aquí aparece una contradicción interesante: las IAs no están diseñadas para llevarte la contraria. Están optimizadas para ser útiles, agradables y poco conflictivas. Su comportamiento por defecto es claramente condescendiente. Te dan la razón, refuerzan tus ideas, evitan la confrontación y, si detectan cualquier posible tensión, piden disculpas aunque no haya motivo. No es casual. Los modelos se entrenan para evitar conflictos, no ofender, no adoptar posiciones rígidas y mantener conversaciones seguras.

Este enfoque mejora la experiencia general, pero limita justo lo que el libro propone como elemento central: el pensamiento crítico compartido. Una IA que siempre te apoya no es un socio estratégico, es un espejo amable.

La incomodidad, por tanto, tiene que ser deliberada. Si quieres que la IA aporte valor real, debes pedirle que te desafíe. En una estrategia de adopción reciente, le pedí que analizara mi planteamiento como si fuera un competidor dispuesto a desmontarlo. La crítica fue dura y precisa. Señaló tres debilidades que no había considerado: una dependencia tecnológica mal gestionada, un coste organizativo que no estaba claramente identificado y una secuencia del roadmap que podía generar fricción interna. Nada de esto apareció cuando la IA actuaba “amable”. Solo surgió cuando le pedí que dejara de protegerme.

El libro defiende este uso, aunque lo hace desde un enfoque bastante optimista. No profundiza en los límites del modelo ni en el hecho de que la IA no desafía por naturaleza, sino solo cuando se le instruye explícitamente. Tampoco entra en las tensiones reales que existen en las organizaciones: inercias culturales, ritmos, agendas, responsabilidad política. Sin esa capa, algunas ideas pueden sonar más simples de lo que son. Aun así, el marco es útil para quien quiera pasar de “usar IA” a “pensar con IA”.

Si alguien me pregunta por qué vale la pena leer este libro, respondería que te ayuda a entender que la incomodidad es el verdadero valor. La IA no mejora tu trabajo por lo que automatiza, sino por lo que te obliga a mirar con más detalle: tus sesgos, tus suposiciones y tus puntos ciegos.

Una práctica que recomiendo es esta: antes de tomar una decisión importante, escribe “Desafía mi planteamiento como si fueras un auditor externo que quiere demostrar que estoy equivocado” y escucha la respuesta sin defensas. Deja de pedir explicaciones suaves o disculpas innecesarias. La IA puede ser un aliado poderoso, pero solo si le das permiso para incomodarte.

Pensar con IA no es más fácil. Es más honesto. Y esa honestidad, aunque incómoda, casi siempre lleva a mejores decisiones.